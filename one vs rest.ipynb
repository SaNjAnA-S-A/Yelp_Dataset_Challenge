{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading libraries\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "import os\n",
    "\n",
    "Shopping = pd.read_csv(open(os.path.join(\"C://Users//hp//Desktop//dma cp\", \"sh_binary.csv\"), 'r', encoding='utf-8'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=Shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.index=[ x for x in range (0,len(df5.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_id</th>\n",
       "      <th>b_name</th>\n",
       "      <th>text</th>\n",
       "      <th>u_id</th>\n",
       "      <th>service</th>\n",
       "      <th>place</th>\n",
       "      <th>price</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jaJnPIX9VxsFyfV5zQwk0g</td>\n",
       "      <td>Coca-Cola Store Las Vegas</td>\n",
       "      <td>Lots of people on the second floor</td>\n",
       "      <td>29yBaTFMSh-l6wNwy9d_mA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     b_id                     b_name  \\\n",
       "0  jaJnPIX9VxsFyfV5zQwk0g  Coca-Cola Store Las Vegas   \n",
       "\n",
       "                                 text                    u_id  service  place  \\\n",
       "0  Lots of people on the second floor  29yBaTFMSh-l6wNwy9d_mA        1      0   \n",
       "\n",
       "   price  product  \n",
       "0      0        0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service', 'price', 'place', 'product']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories =['service','price','place','product']\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "data = df5\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    return cleaned\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in sentence.split():\n",
    "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "data['text'] = data['text'].str.lower()\n",
    "data['text'] = data['text'].apply(cleanHtml)\n",
    "data['text'] = data['text'].apply(cleanPunc)\n",
    "data['text'] = data['text'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemming(sentence):\n",
    "    stemSentence = \"\"\n",
    "    for word in sentence.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stemSentence += stem\n",
    "        stemSentence += \" \"\n",
    "    stemSentence = stemSentence.strip()\n",
    "    return stemSentence\n",
    "data['text'] = data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df5, random_state=42, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "vectorizer.fit(train.text)\n",
    "vectorizer.fit(test.text)\n",
    "x_train = vectorizer.transform(train.text)\n",
    "y_train = train.drop(labels = ['b_id','text'], axis=1)\n",
    "x_test = vectorizer.transform(test.text)\n",
    "y_test = test.drop(labels = ['b_id','text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Processing service comments...**\n",
      "Test accuracy is 0.9315861130020422\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4682\n",
      "           1       1.00      0.66      0.80      1194\n",
      "\n",
      "    accuracy                           0.93      5876\n",
      "   macro avg       0.96      0.83      0.88      5876\n",
      "weighted avg       0.94      0.93      0.93      5876\n",
      "\n",
      "\n",
      "\n",
      "**Processing price comments...**\n",
      "Test accuracy is 0.8994213750850919\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4711\n",
      "           1       0.99      0.50      0.66      1165\n",
      "\n",
      "    accuracy                           0.90      5876\n",
      "   macro avg       0.94      0.75      0.80      5876\n",
      "weighted avg       0.91      0.90      0.89      5876\n",
      "\n",
      "\n",
      "\n",
      "**Processing place comments...**\n",
      "Test accuracy is 0.9183117767188563\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      4612\n",
      "           1       1.00      0.62      0.77      1264\n",
      "\n",
      "    accuracy                           0.92      5876\n",
      "   macro avg       0.95      0.81      0.86      5876\n",
      "weighted avg       0.93      0.92      0.91      5876\n",
      "\n",
      "\n",
      "\n",
      "**Processing product comments...**\n",
      "Test accuracy is 0.9109938733832539\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      5130\n",
      "           1       0.99      0.30      0.46       746\n",
      "\n",
      "    accuracy                           0.91      5876\n",
      "   macro avg       0.95      0.65      0.71      5876\n",
      "weighted avg       0.92      0.91      0.89      5876\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# Using pipeline for applying logistic regression and one vs rest classifier\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('**Processing {} comments...**'.format(category))\n",
    "    \n",
    "    # Training logistic regression model on train data\n",
    "    LogReg_pipeline.fit(x_train, train[category])\n",
    "    \n",
    "    # calculating test accuracy\n",
    "    prediction = LogReg_pipeline.predict(x_test)\n",
    "   \n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(test[category],prediction))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
